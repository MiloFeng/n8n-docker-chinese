# n8n æ€§èƒ½ä¼˜åŒ–æŒ‡å—

æœ¬æ–‡æ¡£æä¾› n8n Docker éƒ¨ç½²çš„æ€§èƒ½ä¼˜åŒ–å»ºè®®å’Œæœ€ä½³å®è·µã€‚

## ğŸ“Š æ€§èƒ½ç›‘æ§

### åŸºç¡€ç›‘æ§

```bash
# æŸ¥çœ‹å®¹å™¨èµ„æºä½¿ç”¨æƒ…å†µ
docker stats

# æŒç»­ç›‘æ§
docker stats --no-stream

# æŸ¥çœ‹ç‰¹å®šå®¹å™¨
docker stats n8n n8n-postgres
```

### è¯¦ç»†ç›‘æ§

```bash
# æŸ¥çœ‹ n8n å†…å­˜ä½¿ç”¨
docker compose exec n8n sh -c 'ps aux | grep node'

# æŸ¥çœ‹æ•°æ®åº“å¤§å°
docker compose exec postgres psql -U n8n n8n -c "
SELECT 
    pg_size_pretty(pg_database_size('n8n')) as db_size,
    pg_size_pretty(pg_total_relation_size('execution_entity')) as executions_size;
"

# æŸ¥çœ‹æ‰§è¡Œè®°å½•æ•°é‡
docker compose exec postgres psql -U n8n n8n -c "
SELECT COUNT(*) FROM execution_entity;
"
```

## ğŸš€ Docker èµ„æºä¼˜åŒ–

### è®¾ç½®èµ„æºé™åˆ¶

ç¼–è¾‘ `docker-compose.yml`,æ·»åŠ èµ„æºé™åˆ¶:

```yaml
services:
  n8n:
    deploy:
      resources:
        limits:
          cpus: '2'        # æœ€å¤§ä½¿ç”¨ 2 ä¸ª CPU æ ¸å¿ƒ
          memory: 2G       # æœ€å¤§ä½¿ç”¨ 2GB å†…å­˜
        reservations:
          cpus: '1'        # ä¿ç•™ 1 ä¸ª CPU æ ¸å¿ƒ
          memory: 1G       # ä¿ç•™ 1GB å†…å­˜
  
  postgres:
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
```

### ä¼˜åŒ– Docker å­˜å‚¨é©±åŠ¨

```bash
# æŸ¥çœ‹å½“å‰å­˜å‚¨é©±åŠ¨
docker info | grep "Storage Driver"

# æ¨èä½¿ç”¨ overlay2
# ç¼–è¾‘ /etc/docker/daemon.json
{
  "storage-driver": "overlay2"
}

# é‡å¯ Docker
sudo systemctl restart docker
```

## ğŸ—„ï¸ æ•°æ®åº“ä¼˜åŒ–

### PostgreSQL ä¼˜åŒ–

#### 1. è°ƒæ•´ PostgreSQL é…ç½®

åˆ›å»º `postgres/postgresql.conf`:
```conf
# å†…å­˜è®¾ç½®
shared_buffers = 256MB
effective_cache_size = 1GB
maintenance_work_mem = 64MB
work_mem = 16MB

# è¿æ¥è®¾ç½®
max_connections = 100

# æŸ¥è¯¢ä¼˜åŒ–
random_page_cost = 1.1
effective_io_concurrency = 200

# WAL è®¾ç½®
wal_buffers = 16MB
min_wal_size = 1GB
max_wal_size = 4GB

# æ£€æŸ¥ç‚¹è®¾ç½®
checkpoint_completion_target = 0.9
```

åœ¨ `docker-compose.yml` ä¸­æŒ‚è½½é…ç½®:
```yaml
postgres:
  volumes:
    - postgres_data:/var/lib/postgresql/data
    - ./postgres/postgresql.conf:/etc/postgresql/postgresql.conf
  command: postgres -c config_file=/etc/postgresql/postgresql.conf
```

#### 2. å®šæœŸæ¸…ç†æ‰§è¡Œè®°å½•

åˆ›å»º `scripts/cleanup-executions.sh`:
```bash
#!/bin/bash

# æ¸…ç† 30 å¤©å‰çš„æ‰§è¡Œè®°å½•
docker compose exec -T postgres psql -U n8n n8n <<EOF
DELETE FROM execution_entity 
WHERE "startedAt" < NOW() - INTERVAL '30 days';

VACUUM ANALYZE execution_entity;
EOF

echo "æ‰§è¡Œè®°å½•æ¸…ç†å®Œæˆ"
```

```bash
chmod +x scripts/cleanup-executions.sh

# æ·»åŠ åˆ° crontab (æ¯å‘¨æ‰§è¡Œ)
0 2 * * 0 /path/to/n8n/scripts/cleanup-executions.sh
```

#### 3. ä¼˜åŒ–ç´¢å¼•

```bash
# è¿›å…¥æ•°æ®åº“
docker compose exec postgres psql -U n8n n8n

# åˆ›å»ºç´¢å¼•
CREATE INDEX IF NOT EXISTS idx_execution_started_at 
ON execution_entity("startedAt");

CREATE INDEX IF NOT EXISTS idx_execution_workflow_id 
ON execution_entity("workflowId");

# åˆ†æè¡¨
ANALYZE execution_entity;
```

### MySQL ä¼˜åŒ–

ç¼–è¾‘ `docker-compose.mysql.yml`,æ·»åŠ  MySQL é…ç½®:
```yaml
mysql:
  command: 
    - --default-authentication-plugin=mysql_native_password
    - --max_connections=200
    - --innodb_buffer_pool_size=512M
    - --innodb_log_file_size=128M
    - --query_cache_size=0
    - --query_cache_type=0
```

## âš™ï¸ n8n é…ç½®ä¼˜åŒ–

### æ‰§è¡Œæ¨¡å¼ä¼˜åŒ–

åœ¨ `.env` ä¸­é…ç½®:

```bash
# æ‰§è¡Œæ¨¡å¼ (main æˆ– queue)
EXECUTIONS_PROCESS=main
EXECUTIONS_MODE=regular

# å¯¹äºé«˜è´Ÿè½½åœºæ™¯,ä½¿ç”¨é˜Ÿåˆ—æ¨¡å¼
# EXECUTIONS_PROCESS=queue
# QUEUE_BULL_REDIS_HOST=redis
# QUEUE_BULL_REDIS_PORT=6379
```

### è¶…æ—¶è®¾ç½®

```bash
# æ‰§è¡Œè¶…æ—¶æ—¶é—´ (ç§’)
EXECUTIONS_TIMEOUT=300
EXECUTIONS_TIMEOUT_MAX=3600

# æ•°æ®ä¿å­˜è®¾ç½®
EXECUTIONS_DATA_SAVE_ON_ERROR=all
EXECUTIONS_DATA_SAVE_ON_SUCCESS=all
EXECUTIONS_DATA_SAVE_MANUAL_EXECUTIONS=true
```

### æ•°æ®ä¿ç•™ç­–ç•¥

```bash
# å¯ç”¨è‡ªåŠ¨æ¸…ç†
EXECUTIONS_DATA_PRUNE=true

# ä¿ç•™å¤©æ•°
EXECUTIONS_DATA_MAX_AGE=168  # 7å¤©

# æ¸…ç†é—´éš” (å°æ—¶)
EXECUTIONS_DATA_PRUNE_TIMEOUT=1
```

### å¹¶å‘é™åˆ¶

```bash
# ç”Ÿäº§ç¯å¢ƒå¹¶å‘é™åˆ¶
N8N_CONCURRENCY_PRODUCTION_LIMIT=10

# å·¥ä½œæµå¹¶å‘é™åˆ¶
EXECUTIONS_CONCURRENCY_MAX=50
```

## ğŸ”„ ä½¿ç”¨ Redis é˜Ÿåˆ—æ¨¡å¼

å¯¹äºé«˜è´Ÿè½½åœºæ™¯,æ¨èä½¿ç”¨ Redis é˜Ÿåˆ—æ¨¡å¼ã€‚

### æ·»åŠ  Redis æœåŠ¡

ç¼–è¾‘ `docker-compose.yml`:
```yaml
services:
  redis:
    image: redis:7-alpine
    container_name: n8n-redis
    restart: unless-stopped
    volumes:
      - redis_data:/data
    networks:
      - n8n-network
    healthcheck:
      test: ['CMD', 'redis-cli', 'ping']
      interval: 5s
      timeout: 5s
      retries: 5

  n8n:
    environment:
      # å¯ç”¨é˜Ÿåˆ—æ¨¡å¼
      - EXECUTIONS_PROCESS=queue
      - QUEUE_BULL_REDIS_HOST=redis
      - QUEUE_BULL_REDIS_PORT=6379
      - QUEUE_BULL_REDIS_DB=0
    depends_on:
      - redis

volumes:
  redis_data:
    driver: local
```

## ğŸ“ˆ å·¥ä½œæµä¼˜åŒ–å»ºè®®

### 1. å‡å°‘ä¸å¿…è¦çš„æ‰§è¡Œ

```bash
# åªä¿å­˜é”™è¯¯æ‰§è¡Œ
EXECUTIONS_DATA_SAVE_ON_SUCCESS=none
EXECUTIONS_DATA_SAVE_ON_ERROR=all
```

### 2. ä½¿ç”¨æ‰¹å¤„ç†

- åˆå¹¶å¤šä¸ªå°ä»»åŠ¡ä¸ºæ‰¹å¤„ç†ä»»åŠ¡
- ä½¿ç”¨ Split In Batches èŠ‚ç‚¹å¤„ç†å¤§æ•°æ®é›†

### 3. ä¼˜åŒ–è½®è¯¢é—´éš”

- é¿å…è¿‡äºé¢‘ç¹çš„è½®è¯¢
- ä½¿ç”¨ Webhook æ›¿ä»£è½®è¯¢

### 4. ç¼“å­˜ç­–ç•¥

- ä½¿ç”¨ Function èŠ‚ç‚¹ç¼“å­˜å¸¸ç”¨æ•°æ®
- åˆ©ç”¨ Redis å­˜å‚¨ä¸´æ—¶æ•°æ®

## ğŸŒ ç½‘ç»œä¼˜åŒ–

### ä½¿ç”¨ CDN

å¯¹äºé™æ€èµ„æº,è€ƒè™‘ä½¿ç”¨ CDN:
```nginx
# nginx.conf
location /static/ {
    proxy_cache my_cache;
    proxy_cache_valid 200 1d;
    proxy_pass http://n8n:5678;
}
```

### å¯ç”¨ Gzip å‹ç¼©

åœ¨ `nginx/nginx.conf` ä¸­æ·»åŠ :
```nginx
http {
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_types text/plain text/css application/json application/javascript;
}
```

## ğŸ’¾ å­˜å‚¨ä¼˜åŒ–

### ä½¿ç”¨ SSD

ç¡®ä¿ Docker æ•°æ®ç›®å½•åœ¨ SSD ä¸Š:
```bash
# æŸ¥çœ‹ Docker æ•°æ®ç›®å½•
docker info | grep "Docker Root Dir"

# å¦‚éœ€è¿ç§»,ç¼–è¾‘ /etc/docker/daemon.json
{
  "data-root": "/path/to/ssd/docker"
}
```

### å®šæœŸæ¸…ç†

```bash
# æ¸…ç†æœªä½¿ç”¨çš„é•œåƒ
docker image prune -a

# æ¸…ç†æœªä½¿ç”¨çš„å·
docker volume prune

# å®Œæ•´æ¸…ç†
docker system prune -a --volumes
```

## ğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•

### æµ‹è¯•æ•°æ®åº“æ€§èƒ½

```bash
# PostgreSQL æ€§èƒ½æµ‹è¯•
docker compose exec postgres pgbench -i -s 10 n8n
docker compose exec postgres pgbench -c 10 -j 2 -t 1000 n8n
```

### æµ‹è¯• n8n å“åº”æ—¶é—´

```bash
# ä½¿ç”¨ Apache Bench
ab -n 1000 -c 10 http://localhost:5678/

# ä½¿ç”¨ curl æµ‹è¯•
time curl http://localhost:5678/
```

## ğŸ” æ€§èƒ½é—®é¢˜è¯Šæ–­

### è¯†åˆ«æ…¢æŸ¥è¯¢

```bash
# PostgreSQL æ…¢æŸ¥è¯¢æ—¥å¿—
docker compose exec postgres psql -U n8n n8n -c "
SELECT 
    query,
    calls,
    total_time,
    mean_time
FROM pg_stat_statements
ORDER BY mean_time DESC
LIMIT 10;
"
```

### åˆ†æå®¹å™¨æ€§èƒ½

```bash
# ä½¿ç”¨ ctop (éœ€è¦å®‰è£…)
brew install ctop  # macOS
ctop

# æˆ–ä½¿ç”¨ docker stats
docker stats --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}"
```

## ğŸ“ æ€§èƒ½ä¼˜åŒ–æ£€æŸ¥æ¸…å•

- [ ] è®¾ç½®åˆç†çš„èµ„æºé™åˆ¶
- [ ] é…ç½®æ•°æ®åº“è¿æ¥æ± 
- [ ] å¯ç”¨æ‰§è¡Œè®°å½•è‡ªåŠ¨æ¸…ç†
- [ ] ä¼˜åŒ–æ•°æ®åº“ç´¢å¼•
- [ ] ä½¿ç”¨ Redis é˜Ÿåˆ—æ¨¡å¼ (é«˜è´Ÿè½½)
- [ ] é…ç½®åˆç†çš„è¶…æ—¶æ—¶é—´
- [ ] å¯ç”¨ Gzip å‹ç¼©
- [ ] ä½¿ç”¨ SSD å­˜å‚¨
- [ ] å®šæœŸå¤‡ä»½å’Œæ¸…ç†
- [ ] ç›‘æ§èµ„æºä½¿ç”¨æƒ…å†µ

## ğŸ¯ æ¨èé…ç½®

### å°å‹éƒ¨ç½² (< 10 ä¸ªå·¥ä½œæµ)

```bash
# Docker èµ„æº
n8n: 1 CPU, 1GB RAM
postgres: 0.5 CPU, 512MB RAM

# n8n é…ç½®
EXECUTIONS_DATA_MAX_AGE=168  # 7å¤©
N8N_CONCURRENCY_PRODUCTION_LIMIT=5
```

### ä¸­å‹éƒ¨ç½² (10-50 ä¸ªå·¥ä½œæµ)

```bash
# Docker èµ„æº
n8n: 2 CPU, 2GB RAM
postgres: 1 CPU, 1GB RAM

# n8n é…ç½®
EXECUTIONS_DATA_MAX_AGE=336  # 14å¤©
N8N_CONCURRENCY_PRODUCTION_LIMIT=10
EXECUTIONS_PROCESS=queue  # ä½¿ç”¨ Redis
```

### å¤§å‹éƒ¨ç½² (> 50 ä¸ªå·¥ä½œæµ)

```bash
# Docker èµ„æº
n8n: 4 CPU, 4GB RAM
postgres: 2 CPU, 2GB RAM
redis: 1 CPU, 1GB RAM

# n8n é…ç½®
EXECUTIONS_DATA_MAX_AGE=720  # 30å¤©
N8N_CONCURRENCY_PRODUCTION_LIMIT=20
EXECUTIONS_PROCESS=queue
```

---

**æç¤º**: æ€§èƒ½ä¼˜åŒ–æ˜¯ä¸€ä¸ªæŒç»­çš„è¿‡ç¨‹,éœ€è¦æ ¹æ®å®é™…ä½¿ç”¨æƒ…å†µä¸æ–­è°ƒæ•´ã€‚

